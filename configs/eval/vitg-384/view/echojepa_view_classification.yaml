# CLASSIFICATION CONFIG
app: vjepa
cpus_per_task: 32
folder: /mnt/custom-file-systems/efs/fs-0049217cdf69186d7_fsap-0fa7145b64eaa046b/vjepa2/evals/vitg-384/classifier
mem_per_gpu: 80G
nodes: 1
tasks_per_node: 8
num_workers: 8

eval_name: video_classification_frozen
resume_checkpoint: false
tag: uhn22k-classifier-echojepa-g-multi

experiment:
  classifier:
    num_heads: 16           # ARCHITECTURE: Must divide 1408 (1408/16 = 88). Do not change.
    num_probe_blocks: 4     # Standard attentive probe depth

  data:
    dataset_type: VideoDataset
    dataset_train: /home/sagemaker-user/user-default-efs/vjepa2/data/csv/uhn_views_22k_train.csv
    dataset_val:   /home/sagemaker-user/user-default-efs/vjepa2/data/csv/uhn_views_22k_val.csv
    num_classes: 13
    resolution: 224
    frames_per_clip: 16
    
    # SAMPLING (Optimized for Cardiac Cycle)
    frame_step: 2           # ~1.28s context
    num_segments: 2         # Efficient temporal coverage
    num_views_per_segment: 1

  optimization:  
    batch_size: 1  
    # PRUNED REGRESSION GRID  
    multihead_kwargs:  
    # --- Group 1: 1e-4 ---  
    - final_lr: 0.0  
      final_weight_decay: 0.01  
      lr: 0.0001  
      start_lr: 0.0001  
      warmup: 0.0  
      weight_decay: 0.01  
    - final_lr: 0.0  
      final_weight_decay: 0.1  
      lr: 0.0001  
      start_lr: 0.0001  
      warmup: 0.0  
      weight_decay: 0.1  
    - final_lr: 0.0  
      final_weight_decay: 0.4  
      lr: 0.0001  
      start_lr: 0.0001  
      warmup: 0.0  
      weight_decay: 0.4  
  
    # --- Group 2: 5e-5 ---  
    - final_lr: 0.0  
      final_weight_decay: 0.01  
      lr: 0.00005  
      start_lr: 0.00005  
      warmup: 0.0  
      weight_decay: 0.01  
    - final_lr: 0.0  
      final_weight_decay: 0.1  
      lr: 0.00005  
      start_lr: 0.00005  
      warmup: 0.0  
      weight_decay: 0.1  
    - final_lr: 0.0  
      final_weight_decay: 0.4  
      lr: 0.00005  
      start_lr: 0.00005  
      warmup: 0.0  
      weight_decay: 0.4  
        
    num_epochs: 20  
    use_bfloat16: true  
    use_pos_embed: false  

model_kwargs:
  # echo checkpoint
  checkpoint: "/mnt/custom-file-systems/efs/fs-0049217cdf69186d7_fsap-0fa7145b64eaa046b/vjepa2/checkpoints/anneal/keep/pt-280-an81.pt"

  # kinetics checkpoint
  # checkpoint: "/mnt/custom-file-systems/efs/fs-0049217cdf69186d7_fsap-0fa7145b64eaa046b/vjepa2/checkpoints/vitg-384.pt"
  
  # module_name: evals.video_classification_frozen.modelcustom.vit_encoder_multiclip_multilevel
  module_name: evals.video_classification_frozen.modelcustom.vit_encoder_multiclip
  
  pretrain_kwargs:
    encoder:
      checkpoint_key: target_encoder
      img_temporal_dim_size: null
      model_name: vit_giant_xformers
      patch_size: 16
      tubelet_size: 2
      uniform_power: true
      use_rope: true
      
  wrapper_kwargs:
    max_frames: 128
    use_pos_embed: false
    # MULTI-LAYER EXTRACTION: Critical for motion tasks
    # Assumes ViT-Giant (40 blocks). Adjust indices if using smaller model.
    # out_layers: [24, 29, 34, 39] # use for multilevel